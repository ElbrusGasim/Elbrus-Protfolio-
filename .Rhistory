vec.7 = seq(0, 20, length = 10)
vec.7
# removing objects
rm(vec.7)
rm(vec.5, vec.6)
# the rep() function allows to create vectors from the pattern
vec.5 = rep(1, 15)
vec.6 = rep(1:5, 2)
vec.5
vec.6
vec.7 = rep(c(1,4,7), c(2,1,2))
vec.7
vec.8 = rep(1:3, 2, length = 5)
vec.8
# Operations on vectors
vec.1 + 2
vec.9 <- vec.1/3
vec.9
vec.7+vec.8 # same length - element by element
vec.6
vec.7
vec.7+vec.6
vec.5+vec.6 # no multiple - error
# Appending vectors, using variables
vec.10 <- c(vec.1, 0, 0, a, c, vec.4)
vec.10
# Selected functions operating on vectors
mean(vec.1)       # mean
median(vec.1)     # median
sum(vec.1)        # sum of vector elements
min(vec.1)        # minimal element
max(vec.1)        # maximal element
length(vec.1)     # number of elements
prod(vec.1)       # product of elements
sort(vec.1)       # sorts the elements from smallest to largest
vec.str <- c("Winston Churchill", name.1, name.2) # string vectors
vec.str
vec.logi <- c(T, FALSE, TRUE, F, logi)            # logi vectors
vec.logi
v2 <- c(5, rep(0.1, 5), rep(1, 5), rep(5,2),NA)
v2 <- c(5, rep(0.1, 5), rep(1, 5), rep(5,2))
# 3. Create a vector vec.a, defined as the sum of vectors from points 1. and 2.
vec.a <- v1 + v2
v2
v2 <- c(5, rep(0.1, 5), rep(1, 5), rep(5,2))
v2
v2 <- c(5, rep(0, 5), rep(1, 5), rep(5,2))
v2
# 3. Create a vector vec.a, defined as the sum of vectors from points 1. and 2.
vec.a <- v1 + v2
# 4. Find the mean of vec.a
mean(vec.a)
# 5. Find the mean of vec.a function, without using the mean() function
mean <- sum(vec.a)/length(vec.a)
# 6. Subtract 3 from vec.a
vec.a - 3
# 7. What is the smallest and the largest value of vec.a
min(vec.a)
vec.b <- sort(vec.a)
# 9. What is the median, min, and max of a vector c(vec.a, vec.b)
median(c(vec.a, vec.b))
min(c(vec.a, vec.b))
max(c(vec.a, vec.b))
# clearing the whole workspace
rm(list = ls())
a <- 10
a == 10
is.na(a)
b <- NA
b == NA
is.na(b)
vec.1 <- c(1:3, NA)
is.na(vec.1)
# NaN is another type of a missing value. It can occur when some undefined operations are tried to be done. For example:
c <- 0/0
c
is.na(c)  # is.na finds NaNs as well
is.nan(c)
is.nan(b) # but is.nan does not find NAs
# operations on vectors with missing values:
vec.2 <- c(1:4)
vec.2
vec.1+vec.2
vec.1 <- c(1, 5, 19, 22, 17, pi, 5)
# you can easilly refer to certain elements of a vector by using the following indexing procedure:
vec.1[5]		        # select the 5th element
vec.1[c(2,6)] 		  # select the 2nd and 6th element
vec.1[5,6]          # error
vec.1[c(2,6)] 		  # select the 2nd and 6th element
vec.1[c(1:5)]	      # select first five elements
vec.1[1:5]          # this time it works
vec.1[-5]           # select all elements but the 5th
vec.1[-(2:5)]       # select all elements but the ones from 2nd to 5th
vec.1[vec.1>5] 	                # select elements greater than zero
vec.1[vec.1>length(vec.1)] 	    # select elements greater than the length
# vector elements can be named and referred to by their names
names(vec.1) <- c("first", "second", "third", "fourth", "fifth", "this is pie", "and a final 5")
vec.1["third"]
vec.1[c("second", "this is pie")]
# you can also create vectors with names
expenses <- c("bow" = 15, "arrow" = 1, "apple" = 0.1, "stuntman" = 20)
expenses
expenses["bow"]
# changing vector elements
vec.1
vec.1[3] <- 17
vec.1
expenses
expenses[c("bow", "apple")] <- c(18, 0.5)
expenses
# adding new elements
vec.1
vec.1 <- c(vec.1, expenses["bow"])
vec.1
# 1. Create a vector named "desk.items" with elements named
desk.item = c(pens = 2, sheets =125, keyboards = 1 screens = 2 cups = 1, fingers = 10, change = 12.34)
# 1. Create a vector named "desk.items" with elements named
desk.item <- c(pens = 2, sheets =125, keyboards = 1 screens = 2 cups = 1, fingers = 10, change = 12.34)
# 1. Create a vector named "desk.items" with elements named
desk.item <- c(pens = 2, sheets =125, keyboards = 1, screens = 2 cups = 1, fingers = 10, change = 12.34)
# 1. Create a vector named "desk.items" with elements named
desk.item <- c(pens = 2, sheets =125, keyboards = 1, screens = 2, cups = 1, fingers = 10, change = 12.34)
desk.item
values 2, 125, 1, 2, 1, 10, 12.34
# 2. Create a vector named "locker.items" with elements named
#pens, sheets, keyboards, screens, cups, fingers, change and values 2, 125, 1, 2, 1, 10, 12.34
# 2. Create a vector named "locker.items" with elements named
# pens, sheets, cups, change and values 10, 500, 1, 0.02
locker.items <- c(pens = 10, sheets = 500, cups = 1, change = 0.02)
locker.items
# 3. How many pens are there in total?
locker.items[pens] + desk.items[pens]
# 3. How many pens are there in total?
locker.items[pens] + desk.items[pens]
# 1. Create a vector named "desk.items" with elements named
desk.item <- c("pens" = 2, sheets =125, keyboards = 1, screens = 2, cups = 1, fingers = 10, change = 12.34)
#pens, sheets, keyboards, screens, cups, fingers, change and values 2, 125, 1, 2, 1, 10, 12.34
# 2. Create a vector named "locker.items" with elements named
# pens, sheets, cups, change and values 10, 500, 1, 0.02
locker.items <- c("pens" = 10, sheets = 500, cups = 1, change = 0.02)
# 3. How many pens are there in total?
locker.items[pens] + desk.items[pens]
# 3. How many pens are there in total?
locker.items["pens"] + desk.items["pens"]
# 1. Create a vector named "desk.items" with elements named
desk.item <- c("pens" = 2, sheets =125, keyboards = 1, screens = 2, cups = 1, fingers = 10, change = 12.34)
desk.item
#pens, sheets, keyboards, screens, cups, fingers, change and values 2, 125, 1, 2, 1, 10, 12.34
# 2. Create a vector named "locker.items" with elements named
# pens, sheets, cups, change and values 10, 500, 1, 0.02
locker.items <- c("pens" = 10, sheets = 500, cups = 1, change = 0.02)
# 3. How many pens are there in total?
locker.items["pens"] + desk.items["pens"]
# 3. How many pens are there in total?
locker.items["pens"] + desk.item["pens"]
# 4. How much money is there in total?
locker.items[change] + desk.item[change]
# 4. How much money is there in total?
locker.items[change] + desk.item[change]
# 1. Create a vector named "desk.items" with elements named
desk.item <- c("pens" = 2, sheets =125, keyboards = 1, screens = 2, cups = 1, fingers = 10, "change" = 12.34)
#pens, sheets, keyboards, screens, cups, fingers, change and values 2, 125, 1, 2, 1, 10, 12.34
# 2. Create a vector named "locker.items" with elements named
# pens, sheets, cups, change and values 10, 500, 1, 0.02
locker.items <- c("pens" = 10, sheets = 500, cups = 1, "change" = 0.02)
# 4. How much money is there in total?
locker.items[change] + desk.item[change]
# 4. How much money is there in total?
locker.items["change"] + desk.item["change"]
# 5. . Create a vector weight containing patient weight measurements: 60,72,57,90,95
# and a vector height containing patient height measurements 1.72, 1.80, 1.65, 1.90, 1.74.
weight <- c(60,72,57,90,95)
height <- c(1.72, 1.80, 1.65, 1.90, 1,74)
# 6. Calculate the BMI of patients. BMI = weight / (height)2
BMI = weight / (height)2
# 6. Calculate the BMI of patients. BMI = weight / (height)2
BMI = weight / (height)*2
# 6. Calculate the BMI of patients. BMI = weight / (height)2
BMI = weight / (height)**2
# 6. Calculate the BMI of patients. BMI = weight / (height)2
BMI = weight / (height)
weight
height
height <- c(1.72, 1.80, 1.65, 1.90, 1.74)
heigh
height
# 6. Calculate the BMI of patients. BMI = weight / (height)2
BMI = weight / (height)**2
BMI
# 7. Sum up the elements of vector weight and divide calculated sum by length of vector weight.
sum(weight)
# 7. Sum up the elements of vector weight and divide calculated sum by length of vector weight.
sum(weight)/length(weight)
# 7. Sum up the elements of vector weight and divide calculated sum by length of vector weight.
sum(weight)/sum(length(weight))
# 	Assign the calculated value to a vector average_weight.
average_weight <- sum(weight)/sum(length(weight))
# 8. Calculate the average value of vector weight using the function mean().
mean(weight)
# 9. Create a character vector FILMS containing three movie titles (any).
FILMS <- c("interstellar", "A beautiful mind", "Jocker")
# 10. Select from vector FILMS elements 1 and 3.
FILMS[c(1,3)]
# 11. Add to the vector FILMS the fourth title of a film (any).
FILMS <- FILMS + "House of cards"
# 11. Add to the vector FILMS the fourth title of a film (any).
FILMS[4] <- FILMS + "House of cards"
# 11. Add to the vector FILMS the fourth title of a film (any).
FILMS <- c(FILMS, "House of cards")
FILMS
source('libraries.R')
#wdbc <- read_csv(url, col_names = columnNames, col_types = NULL)
wdbc <- read.csv('wdbc.csv', header = FALSE, col.names = columnNames)
# use read_csv to the read into a dataframe
# columnNames are missing in the above link, so we need to give them manually.
columnNames <- c("id","diagnosis","radius_mean","texture_mean","perimeter_mean",
"area_mean","smoothness_mean","compactness_mean","concavity_mean",
"concave_points_mean","symmetry_mean","fractal_dimension_mean",
"radius_se","texture_se","perimeter_se","area_se","smoothness_se",
"compactness_se","concavity_se","concave_points_se","symmetry_se",
"fractal_dimension_se","radius_worst","texture_worst","perimeter_worst",
"area_worst","smoothness_worst","compactness_worst","concavity_worst",
"concave_points_worst","symmetry_worst","fractal_dimension_worst")
wdbc <- read_csv(url, col_names = columnNames, col_types = NULL)
wdbc <- read.csv('wdbc.csv', header = FALSE, col.names = columnNames)
source('libraries.R')
download.file(url, 'wdbc.csv')
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
download.file(url, 'wdbc.csv')
# use read_csv to the read into a dataframe
# columnNames are missing in the above link, so we need to give them manually.
columnNames <- c("id","diagnosis","radius_mean","texture_mean","perimeter_mean",
"area_mean","smoothness_mean","compactness_mean","concavity_mean",
"concave_points_mean","symmetry_mean","fractal_dimension_mean",
"radius_se","texture_se","perimeter_se","area_se","smoothness_se",
"compactness_se","concavity_se","concave_points_se","symmetry_se",
"fractal_dimension_se","radius_worst","texture_worst","perimeter_worst",
"area_worst","smoothness_worst","compactness_worst","concavity_worst",
"concave_points_worst","symmetry_worst","fractal_dimension_worst")
wdbc <- read_csv(url, col_names = columnNames, col_types = NULL)
wdbc <- read_csv2(url, col_names = columnNames, col_types = NULL)
install.packages("readr")
library(readr)
wdbc <- read_csv2(url, col_names = columnNames, col_types = NULL)
wdbc <- read.csv('wdbc.csv', header = FALSE, col.names = columnNames)
source('libraries.R')
url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
download.file(url, 'wdbc.csv')
# use read_csv to the read into a dataframe
# columnNames are missing in the above link, so we need to give them manually.
columnNames <- c("id","diagnosis","radius_mean","texture_mean","perimeter_mean",
"area_mean","smoothness_mean","compactness_mean","concavity_mean",
"concave_points_mean","symmetry_mean","fractal_dimension_mean",
"radius_se","texture_se","perimeter_se","area_se","smoothness_se",
"compactness_se","concavity_se","concave_points_se","symmetry_se",
"fractal_dimension_se","radius_worst","texture_worst","perimeter_worst",
"area_worst","smoothness_worst","compactness_worst","concavity_worst",
"concave_points_worst","symmetry_worst","fractal_dimension_worst")
wdbc <- read_csv2(url, col_names = columnNames, col_types = NULL)
wdbc <- read.csv('wdbc.csv', header = FALSE, col.names = columnNames)
glimpse(wdbc)
library(dplyr)
glimpse(mtcars)
glimpse(wdbc)
# Convert the features of the data: wdbc.data
wdbc.data <- as.matrix(wdbc[,c(3:32)])
# Set the row names of wdbc.data
row.names(wdbc.data) <- wdbc$id
# Create diagnosis vector
diagnosis <- as.numeric(wdbc$diagnosis == "M")
nrow(wdbc.data)
apply(wdbc.data, 2, roundSD)
sum(endsWith(colnames(wdbc.data), "_mean"))
sum(endsWith(colnames(wdbc.data), "_se"))
sum(endsWith(colnames(wdbc.data), "_worst"))
table(wdbc$diagnosis)
#What is the mean of each of the numeric columns ?
round(colMeans(wdbc.data),2)
#What is the sd of each of the numeric columns ?
roundSD <- function(x){
round(sd(x),2)
}
apply(wdbc.data, 2, roundSD)
colnames(corMatrix) <- cNames
#How are the variables related to each other ?
corMatrix <- wdbc[,c(3:32)]
# Rename the colnames
cNames <- c("rad_m","txt_m","per_m",
"are_m","smt_m","cmp_m","con_m",
"ccp_m","sym_m","frd_m",
"rad_se","txt_se","per_se","are_se","smt_se",
"cmp_se","con_se","ccp_se","sym_se",
"frd_se","rad_w","txt_w","per_w",
"are_w","smt_w","cmp_w","con_w",
"ccp_w","sym_w","frd_w")
colnames(corMatrix) <- cNames
# Create the correlation matrix
M <- round(cor(corMatrix), 2)
# Create corrplot
corrplot(M, diag = FALSE, method="color", order="FPC", tl.srt = 90)
install.packages("ggplot2")
install.packages("corrplot")
install.packages("xlsx")
library(ggplot2)
library(corrplot)
library(xlsx)
# Create corrplot
corrplot(M, diag = FALSE, method="color", order="FPC", tl.srt = 90)
wdbc.pcov <- princomp(wdbc.data, scores = TRUE)
summary(wdbc.pcov)
#Bi-plot using covariance matrix
cex.before <- par("cex")
par(cex = 0.7)
biplot(wdbc.pcov)
par(cex = cex.before)
Set up 1 x 2 plotting grid
#Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
pr.cvar <- wdbc.pcov$sdev ^ 2
# Variance explained by each principal component: pve
pve_cov <- pr.cvar/sum(pr.cvar)
#Eigen values
round(pr.cvar, 2)
# Percent variance explained
round(pve_cov, 2)
# Cummulative percent explained
round(cumsum(pve_cov), 2)
#Create a plot of variance explained for each principal component.
# Plot variance explained for each principal component
plot(pve_cov, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
#Create a plot of variance explained for each principal component.
# Plot variance explained for each principal component
plot(pve_cov, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
#Set up 1 x 2 plotting grid
par(mfrow = c(1, 1))
#Create a plot of variance explained for each principal component.
# Plot variance explained for each principal component
plot(pve_cov, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Plot cumulative proportion of variance explained
plot(cumsum(pve_cov), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
summary(wdbc.pr)
#Running PCA using correlation matrix:
wdbc.pr <- prcomp(wdbc.data, scale = TRUE, center = TRUE)
summary(wdbc.pr)
round(wdbc.pr$sdev ^2,4)
#Bi-Plot
#Let’s create a bi-plot to visualize this:
cex.before <- par("cex")
par(cex = 0.7)
biplot(wdbc.pr)
par(cex = cex.before)
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
#Create a scatter plot of observations by components 1 and 2
# Scatter plot observations by components 1 and 2
plot(wdbc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
#Let’s also take PC1 vs PC3 plot:
# Repeat for components 1 and 3
plot(wdbc.pr$x[, c(1,3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
# Repeat for components 1 and 3
plot(wdbc.pr$x[, c(1,4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC4")
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
# Repeat for components 1 and 3
plot(wdbc.pr$x[, c(1,5)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC5")
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
# Repeat for components 1 and 6
plot(wdbc.pr$x[, c(1,6)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC6")
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
# Repeat for components 1 and 6
plot(wdbc.pr$x[, c(1,6)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC6")
legend(x="topleft", pch=1, col = c("red", "black"), legend = c("B", "M"))
#Scree plots
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
pr.var <- wdbc.pr$sdev ^ 2
# Assign names to the columns to be consistent with princomp.
# This is done for reporting purposes.
names(pr.var) <- names(pr.cvar)
# Assign names to the columns as it is not done by default.
# This is done to be consistent with princomp.
names(pve) <- names(pve_cov)
# Variance explained by each principal component: pve
pve <- pr.var/sum(pr.var)
# Assign names to the columns as it is not done by default.
# This is done to be consistent with princomp.
names(pve) <- names(pve_cov)
# Eigen values
round(pr.var, 2)
# Percent variance explained
round(pve, 2)
# Cummulative percent explained
round(cumsum(pve), 2)
#Create a plot of variance explained for each principal component.
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
#From the wdbc.pr object, we need to extract the first five PC’s. To do this, let’s first check the variables available for this object.
ls(wdbc.pr)
wdbc.pcs <- wdbc.pr$x[,1:6]
head(wdbc.pcs, 20)
wdbc.pcst <- wdbc.pcs
wdbc.pcst <- cbind(wdbc.pcs, diagnosis)
head(wdbc.pcst)
# Calculate N
N <- nrow(wdbc.pcst)
# Create a random number vector
rvec <- runif(N)
# Select rows from the dataframe
wdbc.pcst.train <- wdbc.pcst[rvec < 0.75,]
wdbc.pcst.test <- wdbc.pcst[rvec >= 0.75,]
# Check the number of observations
nrow(wdbc.pcst.train)
nrow(wdbc.pcst.test)
library(MASS)
wdbc.pcst.train.df <- wdbc.pcst.train
# convert matrix to a dataframe
wdbc.pcst.train.df <- as.data.frame(wdbc.pcst.train)
# Perform LDA on diagnosis
wdbc.lda <- lda(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data = wdbc.pcst.train.df)
wdbc.lda
wdbc.pcst.test.df <- wdbc.pcst.test
# convert matrix to a dataframe
wdbc.pcst.test.df <- as.data.frame(wdbc.pcst.test)
wdbc.lda.predict <- predict(wdbc.lda, newdata = wdbc.pcst.test.df)
ls(wdbc.lda.predict)
# print the predictions
(wdbc.lda.predict.class <- wdbc.lda.predict$class)
(confusionMat <- table(wdbc.lda.predict.class, wdbc.pcst.test.df$diagnosis))
library(vtreat)
# convert wdbc.pcst to a dataframe
wdbc.pcst.df <- as.data.frame(wdbc.pcst)
nRows <- nrow(wdbc.pcst.df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
nRows <- nrow(wdbc.pcst.df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
#3-fold cross validation
install.packages("vtreat)")
library(vtreat)
# convert wdbc.pcst to a dataframe
wdbc.pcst.df <- as.data.frame(wdbc.pcst)
nRows <- nrow(wdbc.pcst.df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
#3-fold cross validation
install.packages("vtreat)")
install.packages("vtreat")
library(vtreat)
# convert wdbc.pcst to a dataframe
wdbc.pcst.df <- as.data.frame(wdbc.pcst)
nRows <- nrow(wdbc.pcst.df)
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)
# examine the split plan
str(splitPlan)
# Run a 3-fold cross validation plan from splitPlan
k <- 3
for ( i in 1:k ) {
split <- splitPlan[[i]]
model <- lda(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data = wdbc.pcst.df[split$train,])
model.pred.cv <- predict(model, newdata = wdbc.pcst.df[split$app,])
confMat <- table(model.pred.cv$class, wdbc.pcst.df$diagnosis[split$app])
print(confMat)
}
# Run a 10-fold cross validation plan from splitPlan
k <- 10
nRows <- nrow(wdbc.pcst.df)
splitPlan <- kWayCrossValidation(nRows, 10, NULL, NULL)
for ( i in 1:k ) {
split <- splitPlan[[i]]
model <- lda(diagnosis ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data = wdbc.pcst.df[split$train,])
model.pred.cv <- predict(model, newdata = wdbc.pcst.df[split$app,])
confMat <- table(model.pred.cv$class, wdbc.pcst.df$diagnosis[split$app])
print(confMat)
}
source('~/Desktop/USL project .R')
# Run a 10-fold cross validation plan from splitPlan
k <- 10
nRows <- nrow(wdbc.pcst.df)
splitPlan <- kWayCrossValidation(nRows, 10, NULL, NULL)
###########################################
##### R: Intro - Class 4b         #########
##### Basic statistical analysis ##########
###########################################
getwd()
setwd("~/Desktop/USL project ")
###########################################
##### R: Intro - Class 4b         #########
##### Basic statistical analysis ##########
###########################################
getwd()
